@article{Li_Knowledge_Distillation_OD_2023,
  author = {Zhihui Li, Pengfei Xu, Xiaojun Chang, Luyao Yang, Yuanyuan Zhang, Lina Yao, Xiaojiang Chen},
  title = {When Object Detection Meets Knowledge Distillation: A Survey},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2023},
  volume = {45},
  number = {8},
  pages = {10555-10572},
  doi = {10.1109/TPAMI.2023.3257546},
  abstract = {This survey comprehensively reviews knowledge distillation (KD)-based object detection (OD) models. The paper analyzes recent developments and key challenges, summarizing various KD strategies for different OD tasks such as incremental OD, small object detection, and weakly/semi-supervised OD. It also explores novel distillation techniques, including different loss functions and feature interactions, highlighting future research directions for KD-based OD models.},
  keywords = {Knowledge distillation, object detection, model compression, feature distillation, incremental learning, weakly supervised learning},
  url = {https://ieeexplore.ieee.org/document/3257546}
}
